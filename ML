=================SLIP 20========================
1) Implement Ridge Regression, Lasso regression model using boston_houses.csv and take only ‘RM’ and ‘Price’ of the houses. divide the data as training and testing data. Fit line using Ridge regression and to find price of a house if it contains 5 rooms. and compare results.

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_squared_error
from sklearn.datasets import load_diabetes

diabetes = load_diabetes()
data = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)
data['Price'] = diabetes.target

X = data[['bmi']]
y = data['Price']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

ridge = Ridge(alpha=1.0)
lasso = Lasso(alpha=0.1)

ridge.fit(X_train, y_train)
lasso.fit(X_train, y_train)

ridge_pred = ridge.predict(X_test)
lasso_pred = lasso.predict(X_test)

ridge_mse = mean_squared_error(y_test, ridge_pred)
lasso_mse = mean_squared_error(y_test, lasso_pred)

print("Ridge Regression MSE:", ridge_mse)
print("Lasso Regression MSE:", lasso_mse)

ridge_price_for_bmi_005 = ridge.predict(pd.DataFrame([[0.05]], columns=['bmi']))[0]
lasso_price_for_bmi_005 = lasso.predict(pd.DataFrame([[0.05]], columns=['bmi']))[0]

print(f"Predicted target with BMI 0.05 (Ridge): ${ridge_price_for_bmi_005:.2f}")
print(f"Predicted target with BMI 0.05 (Lasso): ${lasso_price_for_bmi_005:.2f}")

=========================================================================================
2) Write a python program to implement Decision Tree whether or not to play Tennis.

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn import tree
import matplotlib.pyplot as plt

data = {
    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],
    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],
    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],
    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],
    'PlayTennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']
}

df = pd.DataFrame(data)

le = LabelEncoder()
df_encoded = df.apply(le.fit_transform)

X = df_encoded[['Outlook', 'Temperature', 'Humidity', 'Wind']]
y = df_encoded['PlayTennis']

clf = DecisionTreeClassifier(criterion="entropy")
clf.fit(X, y)

plt.figure(figsize=(12,8))
tree.plot_tree(clf, feature_names=['Outlook', 'Temperature', 'Humidity', 'Wind'], class_names=['No', 'Yes'], filled=True)
plt.show()

example = pd.DataFrame([[1, 2, 0, 1]], columns=['Outlook', 'Temperature', 'Humidity', 'Wind'])
play_prediction = clf.predict(example)
print("Should you play tennis?", "Yes" if play_prediction[0] else "No")

=================================SLIP 18====================================
1) Write a python program to implement k-means algorithm on a Diabetes dataset.

import os
os.environ["OMP_NUM_THREADS"] = "2"

import warnings
warnings.filterwarnings("ignore", category=UserWarning, message=".*KMeans is known to have a memory leak.*")

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.datasets import load_diabetes
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

diabetes = load_diabetes()
X = diabetes.data
y = diabetes.target

df = pd.DataFrame(X, columns=diabetes.feature_names)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
kmeans.fit(X_scaled)

df['Cluster'] = kmeans.labels_

plt.figure(figsize=(10, 6))
sns.scatterplot(x=df['bmi'], y=df['age'], hue=df['Cluster'], palette='Set1', style=df['Cluster'], s=100)
plt.title('K-Means Clustering on Diabetes Dataset')
plt.xlabel('BMI')
plt.ylabel('Age')
plt.legend()
plt.show()

print("Cluster Centers:")
print(kmeans.cluster_centers_)

print(f"\nInertia: {kmeans.inertia_}")

==================================================================
2) Write a python program to implement Polynomial Linear Regression for salary_positions dataset.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split

data = {
    'PositionLevel': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'Salary': [45000, 50000, 60000, 70000, 80000, 90000, 110000, 130000, 150000, 180000]
}

df = pd.DataFrame(data)

X = df[['PositionLevel']].values
y = df['Salary'].values

poly = PolynomialFeatures(degree=4)
X_poly = poly.fit_transform(X)

lin_reg = LinearRegression()
lin_reg.fit(X_poly, y)

plt.figure(figsize=(10, 6))

plt.scatter(X, y, color='red')

X_grid = np.arange(min(X[:, 0]), max(X[:, 0]), 0.1)
X_grid = X_grid.reshape((len(X_grid), 1))
plt.plot(X_grid, lin_reg.predict(poly.transform(X_grid)), color='blue')

plt.title('Polynomial Linear Regression (Salary vs Position Level)')
plt.xlabel('Position Level')
plt.ylabel('Salary')
plt.show()

print("Polynomial Model Coefficients:", lin_reg.coef_)
print("Polynomial Model Intercept:", lin_reg.intercept_)

======================================Slip 14==========================
1) Create a CNN model and train it on mnist handwritten digit dataset. Using model find
out the digit written by a hand in a given image.
Import mnist dataset from tensorflow.keras.datasets.

import numpy as np
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255
x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

model = Sequential()
model.add(Input(shape=(28, 28, 1)))
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=200, verbose=2)

test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print(f"Test accuracy: {test_accuracy:.4f}")

def predict_digit(image):
    image = image.reshape(1, 28, 28, 1).astype('float32') / 255
    prediction = model.predict(image)
    return np.argmax(prediction)

index = 0
plt.imshow(x_test[index].reshape(28, 28), cmap='gray')
plt.title(f"Predicted Label: {predict_digit(x_test[index])}")
plt.show()

======================================================================================
2) Write a python program to find all null values in a given dataset and remove them. Create your own dataset.

import pandas as pd
import numpy as np

data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', None],
    'Age': [24, None, 35, 45, 29, 31],
    'City': ['New York', 'Los Angeles', None, 'Chicago', 'Houston', 'Phoenix'],
    'Salary': [50000, 54000, 58000, None, 62000, 57000]
}

df = pd.DataFrame(data)
print("Original Dataset:\n", df)

null_values = df.isnull().sum()
print("\nNull values in each column:\n", null_values)

df_cleaned = df.dropna()
print("\nDataset after removing rows with null values:\n", df_cleaned)
